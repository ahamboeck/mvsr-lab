{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.keras.layers import Reshape, MaxPooling2D\n",
    "from tensorflow.keras.layers import InputLayer, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.1'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '../data/test/test_video.mp4'  # Change this to the path of your video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "GPU not detected, check installation.\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is detected.\")\n",
    "else:\n",
    "    print(\"GPU not detected, check installation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "Is a GPU available:  False\n"
     ]
    }
   ],
   "source": [
    "# List the devices TensorFlow can use\n",
    "print(\"Available devices:\")\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# Check if a GPU is available\n",
    "print(\"Is a GPU available: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ML model\n",
    "model = tf.keras.models.load_model('../models/model_no_dropout.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get webcam stream\n",
    "cap = cv.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_contours = 25\n",
    "desired_dim = (150, 150)  # Example desired dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.context._EagerDeviceContext at 0x7faebcf2d600>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "tf.device('/GPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mean and standard deviation\n",
    "mean = np.load('../models/mean.npy')\n",
    "std = np.load('../models/std.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert to grayscale for contour detection\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur\n",
    "    gray = cv.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply thresholding\n",
    "    _, thresh = cv.threshold(gray, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "\n",
    "    # Find contours\n",
    "    contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Process only up to `num_contours` (using Python slicing)\n",
    "    for cnt in contours[:num_contours]:\n",
    "        # Get the bounding rectangle for the contour\n",
    "        x, y, w, h = cv.boundingRect(cnt)\n",
    "\n",
    "        # Crop and resize the image\n",
    "        cropped_image = gray[y:y + h, x:x + w]\n",
    "        resized_image = cv.resize(cropped_image, desired_dim)\n",
    "        reshaped_image = (np.array(resized_image).astype('float32') - mean) / std\n",
    "        reshaped_image = reshaped_image.reshape(-1, 150, 150, 1)\n",
    "\n",
    "        # Draw the current contour on the original frame if the model predicts it as true\n",
    "        if model.predict(reshaped_image, verbose = False)[0][1] > 0.90:\n",
    "            cv.drawContours(frame, [cnt], 0, (0, 255, 0), 3)\n",
    "        \n",
    "\n",
    "    # Display the frame with drawn contours\n",
    "    cv.imshow('frame', frame)\n",
    "\n",
    "    # Break the loop on pressing 'q'\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and destroy all windows\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-cv-keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
