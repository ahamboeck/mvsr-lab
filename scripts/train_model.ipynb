{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Reshape, InputLayer, Input, MaxPooling2D, Conv2D, Dense, Flatten, Dropout\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check tensorflow version\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file_path = '../data/train/outputs/image_descriptions.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a directory for saved files\n",
    "output_dir = '../data/train/snippets/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "img_shape_full = (150, 150, 1)\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all .npy files in the directory\n",
    "npy_files = [f for f in os.listdir(output_dir) if f.endswith('.npy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read labels from the text file\n",
    "labels = {}\n",
    "with open(label_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        filename, label = line.strip().split(',')\n",
    "        labels[filename] = int(label)\n",
    "\n",
    "# Load images and their labels based on the filenames\n",
    "images = []\n",
    "image_labels = []\n",
    "for npy_file in sorted(os.listdir(output_dir)): # SUS\n",
    "    if npy_file.endswith('.npy') and npy_file in labels:\n",
    "        img_array = np.load(os.path.join(output_dir, npy_file))\n",
    "        images.append(img_array)\n",
    "        image_labels.append(labels[npy_file])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of images:\", len(images))\n",
    "print(\"Number of labels:\", len(image_labels))\n",
    "assert len(images) == len(image_labels)\n",
    "\n",
    "print(\"Image shape:\", images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming all images are the same size and reshaped properly for input to a CNN\n",
    "images = np.array(images).reshape(-1, 150, 150, 1)  # Reshape for CNN, change shape as necessary\n",
    "\n",
    "# Start constructing the Keras Sequential model.\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer which is similar to a feed_dict in TensorFlow.\n",
    "model.add(InputLayer(input_shape=img_shape_full))\n",
    "\n",
    "# First convolutional layer with ReLU-activation and max-pooling.\n",
    "model.add(Conv2D(kernel_size=3, strides=1, filters=1, padding='same',\n",
    "                activation='relu', name='layer_conv1'))\n",
    "# model.add(Dropout(0.1))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "\n",
    "model.add(Conv2D(kernel_size=3, strides=1, filters=1, padding='same',\n",
    "                activation='relu', name='layer_conv2'))\n",
    "# model.add(Dropout(0.1))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "# Flatten the output of the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Last fully-connected layer with softmax-activation for use in classification.\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model (assuming this is for a classification task)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Show a summary of the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../models/model_no_dropout/'\n",
    "path = base_path + 'model_no_dropout'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'model' is your Keras model\n",
    "\n",
    "# Open a file in write mode\n",
    "with open(path + '.txt', 'w') as f:\n",
    "    # Pass the file handle to the print function of model.summary()\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "print(\"Model summary saved to %s\", path + \".txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "image_labels = np.array(image_labels)\n",
    "print(image_labels)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "image_labels = to_categorical(image_labels)\n",
    "print(image_labels)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, image_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize pixel values to mean 0 and standard deviation 1\n",
    "mean = np.mean(X_train, axis=(0, 1, 2), keepdims=True)\n",
    "std = np.std(X_train, axis=(0, 1, 2), keepdims=True)\n",
    "\n",
    "# Save to a file\n",
    "np.save(base_path + 'mean.npy', mean)\n",
    "np.save(base_path + 'std.npy', std)\n",
    "\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=5,\n",
    "    epochs=6,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test)  # Use test data for validation\n",
    ")\n",
    "\n",
    "model.save(path + '.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set larger font sizes and bold fonts\n",
    "plt.rc('font', size=14)  # controls default text sizes\n",
    "plt.rc('axes', titlesize=16, titleweight='bold', labelsize=14, labelweight='bold')  # fontsize of the axes title and labels\n",
    "plt.rc('xtick', labelsize=12)  # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=12)  # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=12)  # legend fontsize\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(history.history['accuracy'], marker='o', linestyle='-', color='blue')\n",
    "plt.plot(history.history['val_accuracy'], marker='o', linestyle='--', color='green')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(path + '_accuracy.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(history.history['loss'], marker='o', linestyle='-', color='red')\n",
    "plt.plot(history.history['val_loss'], marker='o', linestyle='--', color='purple')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(path + '_loss.png')\n",
    "plt.close()\n",
    "\n",
    "# Predict the values from the test dataset\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred_classes = np.argmax(Y_pred, axis=1) \n",
    "Y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(Y_true, Y_pred_classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='viridis')  # Using 'viridis' for better visibility\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.savefig(path + '_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Plots saved in the 'models' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "model1 = load_model('../models/model_dropout/model_dropout.keras')\n",
    "model2 = load_model('../models/model_no_dropout/model_no_dropout.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_test and y_test are your test datasets\n",
    "y_pred1 = model1.predict(X_test)\n",
    "y_pred2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1_classes = np.argmax(y_pred1, axis=1)\n",
    "y_pred2_classes = np.argmax(y_pred2, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1 = confusion_matrix(y_true_classes, y_pred1_classes)\n",
    "cm2 = confusion_matrix(y_true_classes, y_pred2_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_path = '../models/confusion_matrices/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cm1).to_csv(confusion_matrix_path + 'model_dropout.csv', index=False)\n",
    "pd.DataFrame(cm2).to_csv(confusion_matrix_path + 'model_no_dropout.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the confusion matrices\n",
    "cm1 = pd.read_csv(confusion_matrix_path + 'model_dropout.csv').to_numpy()\n",
    "cm2 = pd.read_csv(confusion_matrix_path + 'model_no_dropout.csv').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 0]\n",
      " [0 2]]\n",
      "[[6 1]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "print(cm1)\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: -1\n",
      "c: 1\n",
      "McNemar's Test Statistic: 0.0\n",
      "P-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Extract b and c for McNemar's test\n",
    "# b: False Positives in cm1 not present in cm2\n",
    "# c: False Positives in cm2 not present in cm1\n",
    "b = cm1[0, 1] - cm2[0, 1]  # FP in Matrix 1 that are TP/TN in Matrix 2\n",
    "c = cm2[0, 1] - cm1[0, 1]  # FP in Matrix 2 that are TP/TN in Matrix 1\n",
    "\n",
    "print(\"b:\", b)\n",
    "print(\"c:\", c)\n",
    "# Create the contingency table for McNemar's test\n",
    "contingency_table = np.array([[0, max(0, b)], [max(0, c), 0]])\n",
    "\n",
    "# Perform McNemar's test\n",
    "result = mcnemar(contingency_table, exact=False)\n",
    "print(\"McNemar's Test Statistic:\", result.statistic)\n",
    "print(\"P-value:\", result.pvalue)\n",
    "\n",
    "# Optional: Save the p-value to a file\n",
    "mcnemar_path = '../models/mcnemar_test_results/'\n",
    "with open(mcnemar_path + 'mcnemar_1_conv.txt', 'w') as file:\n",
    "    file.write(f\"McNemar's Test Statistic: {result.statistic}\\n\")\n",
    "    file.write(f\"P-value: {result.pvalue}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-cv-keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
